%\documentclass[paper,twocolumn,twoside]{geophysics}
\documentclass[manuscript,revised]{geophysics}
%\documentclass[manuscript]{geophysics}

% An example of defining macros
\newcommand{\rs}[1]{\mathstrut\mbox{\scriptsize\rm #1}}
\newcommand{\rr}[1]{\mbox{\rm #1}}

% Extra packages
\usepackage{amsmath}
\usepackage{bm}
\usepackage[pdftex,colorlinks=true]{hyperref}
\hypersetup{
	allcolors=black,
}
\usepackage{lipsum}
\usepackage[table]{xcolor}

\renewcommand{\figdir}{figures} % figure directory

\begin{document}

\title{Fast equivalent layer technique for gravity data processing with BTTB matrix systems}

\renewcommand{\thefootnote}{\fnsymbol{footnote}} 

\ms{GEO-XXXX} % manuscript number

%\address{
%\footnotemark[1]Observat\'{o}rio Nacional, \\
%Department of Geophysics, \\
%Rio de Janeiro, Brazil}
%\author{Diego Takahashi\footnotemark[1], Vanderlei C. Oliveira
%Jr.\footnotemark[1] and Val\'eria C. F. Barbosa\footnotemark[1]}

%\footer{vanderlei@on.br}
%\lefthead{Takahashi, Oliveria Jr. \& Barbosa}
%\righthead{Fast equivalent layer for BTTB systems}

\maketitle

\begin{abstract}

%\lipsum[1]

We have developed an efficient and very fast equivalent-layer technique for gravity data processing by modifying an iterative method grounded on excess mass constraint that does not require the solution of linear systems. Taking advantage of the symmetric Block-Toeplitz Toeplitz-block (BTTB) structure of the sensitivity matrix, that raises when regular grids of observation points and equivalent sources (point masses) are used to set up a fictitious equivalent layer, we have developed an algorithm which greatly reduces the number of flops and RAM memory necessary to estimate a 2D mass distribution over the equivalent layer. The structure of symmetric BTTB matrix consists of the elements of the first column of the sensitivity matrix, which in turn can be embedded into a symmetric Block-Circulant Circulant-Block (BCCB) matrix. Likewise, only the first column of the BCCB matrix is needed to reconstruct the full sensitivity matrix completely. From the first column of BCCB matrix, its eigenvalues can be calculated using the fast Fourier transform, which can be used to readily compute the matrix-vector product of the forward modeling in the fast equivalent-layer technique. As a result, our method is efficient to process very large datasets using either fine- or mid-grid meshes. The larger the dataset, the faster and more efficient our method becomes compared to the available equivalent-layer techniques. Synthetic tests demonstrate the ability of our method to satisfactorily upward- and downward-continuing the gravity data. For example, while our method requires 26:8 seconds to run one million of observations, the fast equivalent-layer technique required 48:3 seconds to run 22,500 observations. Test with real data from Caraj\'as, Brazil, shows its applicability to process very large dataset at low computational cost.

\end{abstract}

\section{Introduction}

%\lipsum[1-5]

The equivalent layer is a well-known technique for processing potential-field data in applied geophysics since 1960. It comes from potential theory as a mathematical solution of the Laplace's equation, in the region above the sources, by using the Dirichlet boundary condition \citep{kellogg1929}.
This theory states that any potential-field data produced by an arbitrary 3D physical-property distribution can be exactly reproduced by a fictitious layer located at any depth and having a continuous 2D physical-property  distribution. In practical situations, the layer is approximated by a finite set of sources (e.g., point masses or dipoles) and their physical properties are estimated by solving a linear system of equations that yield an acceptable potential-field data fit. These fictitious sources are called equivalent sources.

Many previous works have used the equivalent layer as a processing technique of potential-field data. \citet{dampney1969} used the equivalent-layer technique for gridding and for computing the upward continuation of the potential-field data. \citet{cordell1992} and \citet{mendonca-silva1994} used it for interpolating and gridding potential-field data. \citet{emilia1973}, \citet{hansen-miyazaki1984} and \citet{li-oldenburg2010} used it for upward continuation of the potential-field data. \citet{silva1986}, \citet{leao-silva1989}, \citet{guspi-novara2009}, and \citet{oliveirajr-etal2013} used it for reducing the magnetic data to the pole. \citet{boggs-dransfield2004} used it for combining multiple data sets and \citet{barnes-lumley2011} for gradient-data processing.

The classic equivalent-layer formulation consists in estimating the physical-property distribution within a layer, composed by a set of equivalent sources, by solving a linear system of equations formed by harmonic functions (e.g.,the inverse of the distance between the observation point and the equivalent source). When these observation points and equivalent sources are regularly spaced, a Toeplitz system arises. Toeplitz systems are well-known in many branches of science as in (1) mathematics, for solving partial and ordinary diferential equations \citep[e.g.,][]{lin-etal2003}; (2) image processing \citep[e.g.,][]{chan-etal1999} and; (3) computational neuroscience \citep[e.g.,][]{wray-green1994}. \citet{jin2003} and \citet{chan-jin2007} give many examples of applications for Toeplitz systems.

In potential-field methods, the properties of Toeplitz system were used for downward continuation \citep{zhang-etal2016} and for 3D gravity-data inversion using a 2D multilayer model \citep{zhang-wong2015}. In the particular case of gravity data, the kernel generates a linear system with a matrix known as symmetric Block-Toeplitz Toeplitz-Block (BTTB).

A wide variety of applications in mathematics and engineers that fall into Toeplitz systems propelled the development of a large variety of  methods for solving them. %Direct methods were conceived by \citet{levinson1946} and by \citet{trench1964}. Currently the conjugate gradient is used in most cases.
\citet{grenander-szego1984} noticed that a circulant matrix can be diagonalized by taking the fast Fourier trasform (FFT) of its first column, making it possible to calculate the matrix-vector product and solve the system with low computational cost \citep{strang-aarikka1986, olkin1986}. \citet{chan-jin2007} show some preconditioners to embedd the Toeplitz and BTTB matrices into, respectively, circulant matrices and Block-Circulant Circulant-Block (BCCB) by solving the system applying the conjugate gradient method.

Although the use of the equivalent-layer technique increased over the last decades, one of the biggest problem is still its high computational cost for processing large-data sets. \citet{siqueira-etal2017} developed a computationally efficient scheme for processing gravity data. This scheme does not solve a linear system, instead uses an iterative process that corrects the physical-property distribution over the equivalent layer by adding mass corrections that are proportional to the gravity residual. Although efficient, the method presented by \citet{siqueira-etal2017} requires, at each iteration,  the full computation of the forward problem to guarantee the convergence of the algorithm. The time spent on forward modeling accounts for most of the total computation time of their method.

We propose the use of BTTB and BCCB matrices properties to efficiently  solve the forward modeling in method of \citet{siqueira-etal2017}, resulting in a very faster parameter estimation and the possibility to use very large datasets. Here, we show how the system memory (RAM) usage can be drastically decreased by calculating only the first column of the BTTB matrix and embedding into a BCCB matrix. Using the Szeg\"{o} theorema  combined with \cite{strang-aarikka1986}, the matrix-vector product can be accomplished with very low cost, reducing in some orders of magnitude the number of operations required to complete the process. We present synthetic tests to validate our proposal and real field data from Caraj\'as, Brazil to demonstrate its applicability.


\section*{Methodology}

\subsection{Equivalent-layer technique for gravity data processing}

Let $d^{o}_{i}$ be the observed gravity data at
the point $(x_{i}, y_{i}, z_{i})$, $i = 1, ..., N$, of a local Cartesian
system with $x$ axis pointing to north, the $y$ axis pointing to east and 
the $z$ axis pointing downward.
Let us consider an equivalent layer compose by a set of $N$ point masses 
(equivalent sources) over a layer located at depth $z_0$ ($z_0 >z_i$) and whose 
$x$- and $y$- coordinates of each point mass coincide with the corresponding coordinates 
of the observation directly above.
There is a linear relationship that maps the unknown mass distribution onto the gravity 
data given by
\begin{equation}
\mathbf{d}(\mathbf{p}) = \mathbf{A} \mathbf{p} \: ,
\label{eq:predicted-data-vector}
\end{equation}
where $\mathbf{d}$ is an $N \times 1$ vector whose $i$th element is the predicted gravity 
data at the $i$th point ($x_i$,$y_i$,$z_i$), $\mathbf{p}$ is the unknown $N \times 1$ 
parameter vector whose $j$th element $p_j$  is the mass of the $j$th equivalent source 
(point mass) at the $j$th Cartesian coordinates ($x_j$,$y_j$,$z_0$) and $\mathbf{A}$ 
is an $N \times N$  sensitivity matrix whose $ij$th element is given by 
\begin{equation}
a_{ij}= c_{g} \frac{G \, (z_{0} - z_{i})}{\left[(x_{i} - x_{j})^{2} +
(y_{i} - y_{j})^{2} +	(z_{i} - z_{0})^{2} \right]^{\frac{3}{2}}} \; .
\label{eq:aij}
\end{equation}
where $G$ is the Newton's gravitational constant and $c_{g} = 10^{5}$ 
transforms from $\mathrm{m/s^2}$ to mGal.
Notice that the sensitivity matrix depends on the $i$th coordinates of the observations 
and the $j$th coordinates of the equivalent sources. For convenience, we designate 
these coordinates as matrix coordinates and the indices $i$ and $j$ as matrix indices.
In the classical equivalent-layer technique, we estimate the regularized parameter vector 
from the observed gravity data $\mathbf{d}^{o}$ by
\begin{equation}
\hat{\mathbf{p}} = \left( \mathbf{A}^{\top}\mathbf{A} + 
\mu \, \mathbf{I} \right)^{-1}
\mathbf{A}^{\top} \mathbf{d}^{o} \: .
\label{eq:estimated-p-parameter-space}
\end{equation}

\subsection{Fast equivalent-layer technique}
\citet{siqueira-etal2017} developed an iterative least-squares method to estimate the mass distribution over the equivalent layer based on the excess of mass and the positive correlation between the observed gravity data and the masses on the equivalent layer. Those authors showed that the fast equivalent-layer technique has a better computational efficiency than the classical equivalent layer approach (equation \ref{eq:estimated-p-parameter-space}) if the dataset totalize at least 200 observation points, even using a large number of iterations.

Considering each equivalent source (point mass) directly beneath the observation point, the iteration of the Siqueira et al.'s (2017) method starts by an initial approximation of mass disttibution given by

\begin{equation}
\mathbf{p}^0 = \tilde{\mathbf{A}}^{-1} \mathbf{d}^{o} \: ,
\label{eq:initial_m}
\end{equation}
where $\tilde{\mathbf{A}}^{-1}$ is an $N \times N$ diagonal matrix whose

\begin{equation}
\tilde{\mathbf{A}}^{-1} = [\tilde{a}]_{ii}^{-1} = \frac{\Delta s_i}{(2 \pi \, G \, c_g)} \: .
\label{eq:a_approx}
\end{equation}

where $\Delta s_i$ is the $i$th element of surface area located at the $i$th horizontal coordinates $x_i$ and $y_i$ of the $i$th observation.
At each $k$th iteration, a mass correction vector $\mathbf{\Delta p^k}$ is estimated by minimizing the goal function:

\begin{equation}
\phi(\mathbf{\Delta p^k}) = ||\mathbf{d}^{o} - \mathbf{A}\hat{\mathbf{p}}^k - \tilde{\mathbf{A}} \mathbf{\Delta} \hat{\mathbf{p}^k}||_2^2
\label{eq:goal-function_fast}
\end{equation}

\noindent and the masses of the equivalent sources is updated by

\begin{equation}
\hat{\mathbf{p}}^{k+1} = \hat{\mathbf{p}}^{k} + \mathbf{\Delta} \hat{\mathbf{p}}^{k} \: .
\label{eq:update_m}
\end{equation}

\noindent with

\begin{equation}
\mathbf{\Delta} \hat{\mathbf{p}}^{k+1} = \tilde{\mathbf{A}}^{-1} (\mathbf{d}^{o} - \mathbf{A} \hat{\mathbf{p}}^{k}) \: .
\label{eq:update_delta_m}
\end{equation}

%\lstset{language=Python}
%\lstset{frame=lines}
%\lstset{caption={A \textit{Python} algorithm for Siqueira et al.'s (2017) fast equivalent layer.}}
%\lstset{label={lst:code_direct}}
%\lstset{basicstyle=\footnotesize}
%\begin{lstlisting}
%diagonal_A = G*(10**5)*2*pi/(dx*dy)
%for i in range (itmax):
%	res = (data - A.dot(p))
%	delta_p = res/diagonal_A
%	p += delta_p
%\end{lstlisting}

At the $k$th iteration of Siqueira et al.'s (2017) method, the matrix-vector product $\tensor{A} \hat{\mathbf{p}}^{k}$ must be calculated to get a new residual $\mathbf{d^0} - \tensor{A} \hat{\mathbf{p}}^{k}$. This matrix-vector product represents  the bottleneck of the Siqueira et al.'s (2017) method. Considering the limitation of 16 Gb of RAM memory in our system, we could run  Siqueira et al.'s (2017) method only up to 22 500 observation points. Hence, for very large data sets it is costful and can be overwhelming in terms of RAM memory to maintain such operation.

\subsection{Structure of matrix $\mathbf{A}$ for regular grids}

Consider that the observed data are located on an $N_{x} \times N_{y}$ regular grid of
points regularly spaced from $\Delta x$ and $\Delta y$ along the $x$ and $y$ directions,
respectively, on a horizontal plane defined by the constant vertical coordinate $z_{1} < z_{0}$. 
As a consequence, a given pair of matrix coordinates $(x_{i}, y_{i})$, defined by the matrix index 
$i$, $i = 1, \dots, N = N_{x} N_{y}$, is equivalent to a pair of coordinates $(x_{k}, y_{l})$
given by:
\begin{equation}
x_{i} \equiv x_{k} = x_{1} + \left[ k(i) - 1 \right] \, \Delta x \: , 
\label{eq:xi}
\end{equation}
and
\begin{equation}
y_{i} \equiv y_{l} = y_{1} + \left[ l(i) - 1 \right] \, \Delta y \: ,
\label{eq:yi}
\end{equation}
where $k(i)$ and $l(i)$ are integer functions of the matrix index $i$.
These equations can also be used to define the matrix coordinates 
$x_{j}$ and $y_{j}$ associated with the $j$-th equivalent source,
$j = 1, \dots, N = N_{x}N_{y}$. In this case, the integer functions
are evaluated by using the index $j$ instead of $i$.
For convenience, we designate $x_{k}$ and $y_{l}$ as \textit{grid coordinates}
and the indices $k$ and $l$ as \textit{grid indices}, which are computed with
the integer functions.

The integer functions assume different forms depending on the 
orientation of the regular grid of data.
Consider the case in which the grid is oriented along the
$x$-axis (Figure 1a). For convenience, we designate these grids as 
$x$-\textit{oriented grids}. For them, we have the following integer functions:
\begin{equation}
i(k, l) = (l - 1) \, N_{x} + k \quad ,
\label{eq:i-x-oriented}
\end{equation}
\begin{equation}
l(i) = \Bigg\lceil \frac{i}{N_{x}} \Bigg\rceil
\label{eq:l-x-oriented}
\end{equation}
and
\begin{equation}
k(i)  = i - \Bigg\lceil \frac{i}{N_{x}} \Bigg\rceil N_{x} + N_{x} \quad ,
\label{eq:k-x-oriented}
\end{equation}
where $\lceil \cdot \rceil$ denotes the ceiling function \citep[][ p. 67]{graham-etal1994}.
These integer functions are defined in terms of the matrix index $i$, but they can 
be defined in the same way by using the index $j$.
Figure 1a illustrates an $x$-oriented grid defined by $N_{x} = 4$ and $N_{y} = 3$.
In this example, the matrix coordinates $x_{7}$ and $y_{7}$, defined by the matrix index $i = 7$ (or $j = 7$), 
are equivalent to the grid coordinates $x_{3}$ and $y_{2}$, which are defined by the grid indices
$k = 3$ and $l = 2$, respectively. These indices are computed with equations \ref{eq:l-x-oriented}
and \ref{eq:k-x-oriented}, by using the matrix index $i = 7$ (or $j = 7$).

Now, consider the case in which the regular grid of data is oriented along 
the $y$-axis (Figure 1b). For convenience, we call them $y$-\textit{oriented grids}.
Similarly to $x$-oriented grids, we have the following integer functions associated with
$y$-oriented grids:
\begin{equation}
i(k, l) = (k - 1) \, N_{y} + l \quad ,
\label{eq:i-y-oriented}
\end{equation}
\begin{equation}
k(i) = \Bigg\lceil \frac{i}{N_{y}} \Bigg\rceil
\label{eq:k-y-oriented}
\end{equation}
and
\begin{equation}
l(i) = i - \Bigg\lceil \frac{i}{N_{y}} \Bigg\rceil N_{y} + N_{y} \quad .
\label{eq:l-y-oriented}
\end{equation}
Figure 1b illustrates an $y$-oriented grid defined by $N_{x} = 4$ and $N_{y} = 3$.
In this example, the matrix coordinates $x_{7}$ and $y_{7}$, defined by the matrix index 
$i = 7$ (or $j = 7$), are equivalent to the grid coordinates $x_{3}$ and $y_{1}$, which are 
defined by the grid indices $k = 3$ and $l = 1$, respectively. Differently from the example
shown in Figure 1a, the grid indices of the present example are 
computed with equations \ref{eq:k-y-oriented} and \ref{eq:l-y-oriented}, by using the 
matrix index $i = 7$ (or $j = 7$).

The element $a_{ij}$ (equation \ref{eq:aij}) can be rewritten 
by using equations \ref{eq:xi} and \ref{eq:yi}, giving rise to:
\begin{equation}
a_{ij} = \frac{G \, \Delta z \, 10^{-5}}{ \left[ 
	\left( \Delta k_{ij} \, \Delta x \right)^{2} + 
	\left( \Delta l_{ij} \, \Delta y \right)^{2} + 
	\left( \Delta z \right)^{2} \right]^{\frac{3}{2}}} \: ,
\label{eq:aij-regular-grids}
\end{equation}
where $\Delta z = z_{0} - z_{1}$, 
$\Delta k_{ij} = k(i) - k(j)$ (equations \ref{eq:k-x-oriented} and \ref{eq:k-y-oriented}) and
$\Delta l_{ij} = l(i) - l(j)$ (equations \ref{eq:l-x-oriented} and \ref{eq:l-y-oriented}).
Notice that the structure of matrix $\mathbf{A}$ (equation \ref{eq:predicted-data-vector}) for 
the case in which its elements are given by $a_{ij}$ (equation \ref{eq:aij-regular-grids}) is 
defined by the coefficients $\Delta k_{ij}$ and $\Delta l_{ij}$.

For $x$-oriented grids, the coefficients $\Delta k_{ij}$ and $\Delta l_{ij}$ are 
computed by using equations \ref{eq:k-x-oriented} and \ref{eq:l-x-oriented}, respectively.
In this case, $\mathbf{A}$ (equation \ref{eq:predicted-data-vector}) is a 
particular type of matrix called symmetric doubly block Toeplitz \citep[][ p. 28]{jain1989}
or symmetric Block-Toeplitz Toeplitz-Block (BTTB) matrix \citep[][ p. 67]{chan-jin2007}.
We opted for using the second term. This matrix is 
composed of $N_{y} \times N_{y}$ blocks, where each block is a symmetric Toeplitz matrix
formed by $N_{x} \times N_{x}$ elements.
For $y$-oriented grids, the coefficients $\Delta k_{ij}$ and $\Delta l_{ij}$ are 
computed by using equations \ref{eq:k-y-oriented} and \ref{eq:l-y-oriented}, respectively.
In this case, $\mathbf{A}$ (equation \ref{eq:predicted-data-vector}) is a 
symmetric BTTB matrix composed of $N_{x} \times N_{x}$ blocks, where each block is a
symmetric Toeplitz matrix formed by $N_{y} \times N_{y}$ elements.
In both cases, the blocks lying at the same diagonal are equal to each other
and those located above the main diagonal are equal to those located below.
These symmetries come from the fact that the coefficients
$\Delta k_{ij}$ and $\Delta l_{ij}$ are squared at the denominator of 
$a_{ij}$ (equation \ref{eq:aij-regular-grids}).

We represent $\mathbf{A}$ as a grid of $Q \times Q$ blocks $\mathbf{A}_{q}$, 
$q = 0, \dots, Q - 1$, where each block has $P \times P$ elements.
For $x$-oriented grids, the index $q$ varies from $0$, at the main diagonal,
to $Q - 1$, at the corners of $\mathbf{A}$, where $Q = N_{y}$.
In this case, the index $q$ is defined as an integer function
of the matrix indices $i$ and $j$ as follows:
\begin{equation}
q(i, j) = \; \mid l(i) - l(j) \mid \quad ,
\label{eq:q-x-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-x-oriented}.
The elements forming the first column of $\mathbf{A}_{q}$ are conveniently 
represented as $a^{q}_{p}$, $p = 0, \dots, P - 1$, where $q \equiv q(i, j)$ 
(equation \ref{eq:q-x-oriented}), $P = N_{x}$ and the subscript index $p$ is defined by 
the following integer function:
\begin{equation}
p(i, j) = \; \mid k(i) - k(j) \mid \quad ,
\label{eq:p-x-oriented}
\end{equation}
where $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-x-oriented}.
For $y$-oriented grids, the index $q$ varies from $0$, at the main diagonal,
to $Q - 1$, at the corners of $\mathbf{A}$, where $Q = N_{x}$.
In such grids, $q$ is given by:
\begin{equation}
q(i, j) = \; \mid k(i) - k(j) \mid \quad ,
\label{eq:q-y-oriented}
\end{equation}
where the integer functions $k(i)$ and $k(j)$ are defined by equation \ref{eq:k-y-oriented}.
In this case, the elements forming the first column of $\mathbf{A}_{q}$ are 
represented as $a^{q}_{p}$, $p = 0, \dots, P - 1$, where $q \equiv q(i, j)$ 
(equation \ref{eq:q-y-oriented}), $P = N_{y}$ and the subscript index $p$ is defined by:
\begin{equation}
p(i, j) = \; \mid l(i) - l(j) \mid \quad ,
\label{eq:p-y-oriented}
\end{equation}
where $l(i)$ and $l(j)$ are defined by equation \ref{eq:l-y-oriented}.
For convenience, we designate the indices $q$ and $p$ as \textit{block indices}.

It is important noting that different matrix indices $i$ or $j$ produce the same 
absolute values for the grid indices $k$ (equations \ref{eq:k-x-oriented} and
\ref{eq:k-y-oriented}) and $l$ (equations \ref{eq:l-x-oriented} and
\ref{eq:l-y-oriented}). As a consequence, different pairs of matrix indices $i$
and $j$ generate the same absolute values for the coefficients $\Delta k_{ij}$ and
$\Delta l_{ij}$ that compose the denominator of $a_{ij}$ 
(equation \ref{eq:aij-regular-grids}). It means that elements $a_{ij}$ defined
by different matrix indices $i$ and $j$ have the same value. The key point for
understanding the structure of matrix $\mathbf{A}$ is then, given a single element $a_{ij}$
defined by matrix indices $i$ and $j$, compute the grid indices 
$k$ (equations \ref{eq:k-x-oriented} and \ref{eq:k-y-oriented}) and
$l$ (equations \ref{eq:l-x-oriented} and \ref{eq:l-y-oriented}).
These grid indices are used to 
(1) compute the coefficients $\Delta k_{ij}$ and 
$\Delta l_{ij}$ and determine the value of $a_{ij}$ with equation 
\ref{eq:aij-regular-grids} and 
(2) compute the block indices $q$ (equations \ref{eq:q-x-oriented}, 
and \ref{eq:q-y-oriented}) and $p$ (equations \ref{eq:p-x-oriented} and
and \ref{eq:p-y-oriented}) and determine the positions where $a_{ij}$ appears
in matrix $\mathbf{A}$.

Consider the $x$-oriented grid of $N_{x} \times N_{y}$ points shown in Figure 1a, 
with $N_{x} = 4$, $N_{y} = 3$ and $N = N_{x} \, N_{y} = 12$.
This grid results in a matrix $\mathbf{A}$ given by:
\begin{equation}
\mathbf{A} = \begin{bmatrix}
\mathbf{A}_{0} & \mathbf{A}_{1} & \mathbf{A}_{2} \\
\mathbf{A}_{1} & \mathbf{A}_{0} & \mathbf{A}_{1} \\
\mathbf{A}_{2} & \mathbf{A}_{1} & \mathbf{A}_{0}
\end{bmatrix} \quad ,
\label{eq:A-x-oriented-example}
\end{equation}
where $\mathbf{A}_{q}$, $q = 0, \dots, Q -1$, $Q = N_{y}$, 
are symmetric Toeplitz matrices given by:
\begin{equation}
\mathbf{A}_{q} = \begin{bmatrix}
a^{q}_{0} & a^{q}_{1} & a^{q}_{2} & a^{q}_{3} \\
a^{q}_{1} & a^{q}_{0} & a^{q}_{1} & a^{q}_{2} \\
a^{q}_{2} & a^{q}_{1} & a^{q}_{0} & a^{q}_{1} \\
a^{q}_{3} & a^{q}_{2} & a^{q}_{1} & a^{q}_{0}
\end{bmatrix} \quad ,
\label{eq:Aq-x-oriented}
\end{equation}
with elements $a^{q}_{p}$ defined by $p = 0, \dots, P - 1$, $P = N_{x}$.
To illustrate the relationship between the block indices ($q$ and $p$) and the matrix indices 
($i$ and $j$), consider the element $a_{ij}$ defined by $i = 2$ and $j = 10$, which is
located at the upper right corner of $\mathbf{A}$, in the 2nd line and 10th column.
By using equations \ref{eq:l-x-oriented} and \ref{eq:k-x-oriented}, we obtain the 
grid indices $l(i) = 1$, $l(j) = 3$, $k(i) = 2$ and $k(j) = 2$.
These grid indices result in the coefficients $\Delta k_{ij} = 0$ and $\Delta l_{ij} = -2$,
which are used to compute the element $a_{ij}$ (equation \ref{eq:aij-regular-grids}),
as well as in the block indices $q = 2$ (equation \ref{eq:q-x-oriented}) and 
$p = 0$ (equation \ref{eq:p-x-oriented}).
These block indices indicate that this element $a_{ij}$ appears in the main diagonal
of the blocks $\mathbf{A}_{2}$, which are located at the corners of $\mathbf{A}$.
To verify this, let us take the matrix indices associated with these elements.
They are $(i, j)$ = $(1, 9)$, $(2, 10)$, $(3, 11)$, $(4, 12)$, $(9, 1)$, $(10, 2)$, 
$(11, 3)$ and $(12, 4)$. By using these matrix indices, it is easy to verify that all
of them produce the same grid indices $l(i)$, $l(j)$, $k(i)$ and $k(j)$ 
(equations \ref{eq:l-x-oriented} and \ref{eq:k-x-oriented}) as those associated with
the element defined by $i = 2$ and $j = 10$. Consequently, all of them produce
elements $a_{ij}$ (equation \ref{eq:aij-regular-grids}) having the same value.
Besides, it is also easy to verify that all these matrix indices produce the same block
indices $q = 2$ (equation \ref{eq:q-x-oriented}) and $p = 0$ (equation \ref{eq:p-x-oriented}).
By repeating this procedure for all elements $a_{ij}$, $i = 0, 1, 2, 3$, $j = 0, 1, 2$, 
forming the matrix $\mathbf{A}$ obtained from our $x$-oriented grid (Figure 1a),
we can verify the well-defined pattern represented by equations 
\ref{eq:A-x-oriented-example} and \ref{eq:Aq-x-oriented}.
This procedure can also be used to verify that the matrix $\mathbf{A}$ obtained
from the $y$-oriented grid illustrated in Figure 1b is given by
\begin{equation}
\mathbf{A} = \begin{bmatrix}
\mathbf{A}_{0} & \mathbf{A}_{1} & \mathbf{A}_{2} & \mathbf{A}_{3} \\
\mathbf{A}_{1} & \mathbf{A}_{0} & \mathbf{A}_{1} & \mathbf{A}_{2} \\
\mathbf{A}_{2} & \mathbf{A}_{1} & \mathbf{A}_{0} & \mathbf{A}_{1} \\
\mathbf{A}_{3} & \mathbf{A}_{2} & \mathbf{A}_{1} & \mathbf{A}_{0}
\end{bmatrix} \quad ,
\label{eq:A-y-oriented-example}
\end{equation}
where $\mathbf{A}_{q}$, $q = 0, \dots, Q - 1$, $Q = N_{x}$, 
are symmetric Toeplitz matrices given by:
\begin{equation}
\mathbf{A}_{q} = \begin{bmatrix}
a^{q}_{0} & a^{q}_{1} & a^{q}_{2} \\
a^{q}_{1} & a^{q}_{0} & a^{q}_{1} \\
a^{q}_{2} & a^{q}_{1} & a^{q}_{0}
\end{bmatrix} \quad ,
\label{eq:Aq-y-oriented}
\end{equation}
with elements $a^{q}_{p}$ defined by $p = 0, \dots, P - 1$, $P = N_{y}$.

\subsection{BTTB matrix-vector product}

\citet{siqueira-etal2017} developed a computationally efficient scheme for processing gravity data. 
This scheme does not solve a linear system for estimating the parameter vector $\mathbf{p}$
(equation \ref{eq:predicted-data-vector}).
Instead, it uses an iterative process that corrects $\mathbf{p}$ based on the residuals. 
Although computationally efficient, the method presented by \citet{siqueira-etal2017} requires, 
at each iteration, the matrix-vector product $\mathbf{A}\mathbf{p}$ for computing the 
predicted data vector $\mathbf{d}(\mathbf{p})$ (equation \ref{eq:predicted-data-vector}).
This step accounts for most of the total computation time of their algorithm and can suffer
from RAM memory shortage when large data sets are used.
This computational load can be drastically lessen by exploring the well-defined structure of 
matrix $\mathbf{A}$ (equation \ref{eq:predicted-data-vector}) for the particular case in which 
its elements $a_{ij}$ are defined by equation \ref{eq:aij-regular-grids}. 
In this case, $\mathbf{A}$ is a symmetric BTTB matrix (as illustrated by equations
\ref{eq:A-x-oriented-example}, \ref{eq:Aq-x-oriented}, \ref{eq:A-y-oriented-example} and
\ref{eq:Aq-y-oriented}) and the predicted data vector 
$\mathbf{d}(\mathbf{p})$ (equation \ref{eq:predicted-data-vector}) can be efficiently
computed by using the two-dimensional Discrete Fourier Transform (DFT).

\begin{equation}
\mathbf{d}(\mathbf{p}) = \begin{bmatrix}
\mathbf{d}_{0}(\mathbf{p}) \\
\mathbf{d}_{1}(\mathbf{p}) \\
\vdots \\
\mathbf{d}_{Q - 1}(\mathbf{p})
\end{bmatrix}_{N \times 1}
\label{eq:predicted-data-vector-partitioned}
\end{equation}
and
\begin{equation}
\mathbf{p} = \begin{bmatrix}
\mathbf{p}_{0} \\
\mathbf{p}_{1} \\
\vdots \\
\mathbf{p}_{Q - 1}
\end{bmatrix}_{N \times 1} \quad ,
\label{eq:parameter-vector-partitioned}
\end{equation}
where $\mathbf{d}_{q}(\mathbf{p})$ and $\mathbf{p}_{q}$, $q = 0, \dots, Q - 1$,
are $P \times 1$ vectors. Notice that $q$ is the block index defined by equations 
\ref{eq:q-x-oriented} and \ref{eq:q-y-oriented}, $Q$ defines the number of blocks
$\mathbf{A}_{q}$ forming $\mathbf{A}$ and $P$ defines the number of elements forming 
each block $\mathbf{A}_{q}$.

\begin{equation}
\mathbf{w} = \mathbf{C} \mathbf{v} \: ,
\label{eq:embedding-BCCB-matrix-vector-product}
\end{equation}
where
\begin{equation}
\mathbf{w} = \begin{bmatrix}
\mathbf{w}_{0} \\
\mathbf{w}_{1} \\
\vdots \\
\mathbf{w}_{Q - 1} \\
\mathbf{0}_{(2QP) \times 1}
\end{bmatrix}_{(4QP) \times 1} \quad ,
\label{eq:w-vector}
\end{equation}
\begin{equation}
\mathbf{w}_{q} = \begin{bmatrix}
\mathbf{d}_{q}(\mathbf{p}) \\
\mathbf{0}_{P \times 1}
\end{bmatrix}_{(2P) \times 1}
\label{eq:wq-vector} \quad ,
\end{equation}
\begin{equation}
\mathbf{v} = \begin{bmatrix}
\mathbf{v}_{0} \\
\mathbf{v}_{1} \\
\vdots \\
\mathbf{v}_{Q - 1} \\
\mathbf{0}_{(2QP) \times 1}
\end{bmatrix}_{(4QP) \times 1} \quad ,
\label{eq:v-vector}
\end{equation}
and
\begin{equation}
\mathbf{v}_{q} = \begin{bmatrix}
\mathbf{p}_{q} \\
\mathbf{0}_{P \times 1}
\end{bmatrix}_{(2P) \times 1}
\label{eq:vq-vector} \quad ,
\end{equation}
with $\mathbf{d}_{q}(\mathbf{p})$ and $\mathbf{p}_{q}$ defined by
equations \ref{eq:predicted-data-vector-partitioned} and 
\ref{eq:parameter-vector-partitioned}, respectively.

\begin{equation}
\tensor{C} =
\begin{bmatrix}
	\tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} \cr
	\tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} \cr
	\tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} \cr
	\tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} \cr
	\tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} \cr
	\tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} & \tensor{C_{2}} \cr
	\tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}} & \tensor{C_{1}} \cr
	\tensor{C_{1}} & \tensor{C_{2}} & \tensor{C_{3}} & \tensor{0} & \tensor{C_{3}} & \tensor{C_{2}} & \tensor{C_{1}} & \tensor{C_{0}}
\end{bmatrix},
\label{eq:circulant_elements}
\end{equation}
where each block $\mathbf{C}_{l}$ is:

\begin{equation}
\tensor{C}_{l} =
\begin{bmatrix}
	\tensor{A}_{l} & \times \cr
	\times & \tensor{A}_{l}
\end{bmatrix} =
\begin{bmatrix}
	a_{0}^{\ell} & a_{1}^{\ell} & a_{2}^{\ell} & 0^{\ell} & a_{2}^{\ell} & a_{1}^{\ell} \cr
	a_{1}^{\ell} & a_{0}^{\ell} & a_{1}^{\ell} & a_{2}^{\ell} & 0^{\ell} & a_{2}^{\ell} \cr
	a_{2}^{\ell} & a_{1}^{\ell} & a_{0}^{\ell} & a_{1}^{\ell} & a_{2}^{\ell} & 0^{\ell} \cr
	0^{\ell} & a_{2}^{\ell} & a_{1}^{\ell} & a_{0}^{\ell} & a_{1}^{\ell} & a_{2}^{\ell} \cr
	a_{2}^{\ell} & 0^{\ell} & a_{2}^{\ell} & a_{0}^{\ell} & a_{0}^{\ell} & a_{1}^{\ell} \cr
	a_{1}^{\ell} & a_{2}^{\ell} & 0^{\ell} & a_{2}^{\ell} & a_{1}^{\ell} & a_{0}^{\ell}
\end{bmatrix}.
\label{eq:toeplitz_circulant_element}
\end{equation}

The matrix $\mathbf{C}$ is a $4N_x N_y \times 4N_x N_y$ Block-Circulant matrix formed by Circulant-Blocks matrices. This matrix is formed by a grid of $2N_x \times 2N_x$ blocks, where each block is a $2N_y \times 2N_y$ matrix.

%Instead of calculating the product $\mathbf{d} = \mathbf{A} \mathbf{p}$ (equation \ref{eq:predicted-data-vector}), we now carry the following multiplication:

%\begin{equation}
%\mathbf{C} \mathbf{v} = \mathbf{q} \: ,
%\label{eq:BCCB_vector_product}
%\end{equation}
%where $\mathbf{v}$ and $\mathbf{q}$ are $4N_x N_y \times 1$ vectors given, respectively, by:

%\begin{equation}
%\mathbf{v} =
%\begin{bmatrix}
%	\mathbf{v}_{0} \cr
%	\mathbf{v}_{1} \cr
%	\vdots \cr
%	\mathbf{v}_{N_x- 1} \cr
%	\mathbf{0}_{(2 N_x N_y)}
%\end{bmatrix}
%\end{equation}

%\noindent and
%
%\begin{equation}
%\mathbf{q} =
%\begin{bmatrix}
%	\mathbf{q}_{0} \cr
%	\mathbf{q}_{1} \cr
%	\vdots \cr
%	\mathbf{q}_{N_x - 1} \cr
%	\mathbf{\dagger}_{(2 N_x N_y)}
%\end{bmatrix} \: ,
%\end{equation}
%where $\mathbf{0}_{(2 N_x N_y)}$ is a $2 N_x N_y \times 1$ vector of zeros, $\mathbf{\dagger}_{(2 N_x N_y)}$ is $2 N_x N_y \times 1$ vector to be drop out and $\mathbf{v}_{\ell}$ and $\mathbf{q}_{\ell}$, $\ell = 0, \dots, N_x-1$ are:
%
%\begin{equation}
%\mathbf{v}_{\ell} =
%\begin{bmatrix}
%	\mathbf{p}_{\ell} \cr
%	\mathbf{0}_{(N_y)}
%\end{bmatrix}
%\end{equation}
%
%\noindent and
%
%\begin{equation}
%\mathbf{q}_{\ell} =
%\begin{bmatrix}
%	\mathbf{d}_{\ell} \cr
%	\mathbf{\dagger}_{(N_y)}
%\end{bmatrix} \: ,
%\end{equation}
%where $\mathbf{0}_{(N_y)}$ is a $N_y \times 1$ vector of zeros, $\mathbf{\dagger}_{(N_y)}$ is a $N_y \times 1$ vector to be drop out and $\mathbf{d}_{\ell}$ and $\mathbf{p}_{\ell}$ are $N_y \times 1$ vectors partitioned from the original $\mathbf{d}$ and $\mathbf{p}$ vectors (equation \ref{eq:predicted-data-vector}).

As demonstrated by \cite{grenander-szego1984}, circulant matrices can be diagonalized by taking the discrete Fourier transform (DFT), i.e., its eigenvalues can be easily calculated by a fast algorithm of DFT. For BCCB matrices \cite{chan-jin2007} demonstrate that they satisfy:

\begin{equation}
\mathbf{C} = \left(\mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right)^{\ast} \mathbf{\Lambda}\left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \: ,
\label{eq:fft_BCCB}
\end{equation}

\noindent where $\mathbf{F}_{(2N_y)}$ and $\mathbf{F}_{(2N_x)}$ are the matrices of the discrete Fourier transform, ``$\otimes$'' represents the Kronecker product, ``$\ast$'' the conjugate matrix and $\mathbf{\Lambda}$ is the diagonal matrix $4N_xN_y \times 4N_xN_y$ containing the eigenvalues of $\mathbf{C}$. By proper manipulating equation \ref{eq:fft_BCCB} it is possible to calculate the eigenvalues of the BCCB matrix using only its first column:

\begin{eqnarray}
\left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \mathbf{C} = \mathbf{\Lambda} \, \left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \\
\left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \, \mathbf{C} \, \mathbf{t}_{1} = \mathbf{\Lambda} \, \left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \, \mathbf{t}_{1} \\
\left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \, \mathbf{c}_{0} = \mathbf{\Lambda} \, \frac{1}{\sqrt{4N_xN_y}}\mathbf{1}_{(4N_xN_y)} \\
\left( \mathbf{F}_{(2N_y)} \otimes \mathbf{F}_{(2N_x)} \right) \, \mathbf{c}_{0} = \frac{1}{\sqrt{4N_xN_y}} \mathbf{\lambda} \quad ,
\label{eq:fft_BCCB_column}
\end{eqnarray}

\noindent where $\mathbf{t}_{1}$ is a $4N_xN_y \times 1$ vector with first element equal to 1 and all the remaining elements equal to 0, the vector $\mathbf{c}_{0}$ $4N_xN_y \times 1$ is the first column of $\mathbf{C}$, $\mathbf{1}_{(4N_xN_y)}$ is a $4N_xN_y \times 1$ with all elements equal to 1 and $\mathbf{\lambda}$ is a vector representing the diagonal of $\mathbf{\Lambda}$ (the eigenvalues of $\mathbf{C}$). Note that using one of the Kronecker product properties equation \ref{eq:fft_BCCB_column} can be calculated using the 2D-DFT \citep{jain1989}:

\begin{eqnarray}
\mathbf{F}_{(2N_x)} \mathbf{G} \, \mathbf{F}_{(2N_y)} &= \frac{1}{\sqrt{4N_xN_y}} \mathbf{L}
\quad ,
\label{eq:fft_BCCB_column_2D}
\end{eqnarray}

\noindent where $\mathbf{G}$ is a $2N_x \times 2N_y$ row-oriented matrix containing the elements of the first column $\mathbf{c}_{0}$ of $\mathbf{C}$ and $\mathbf{L}$ is a $2N_x \times 2N_y$ row-oriented matrix containing the eigenvalues $\mathbf{\lambda}$.

By substituting equation \ref{eq:fft_BCCB} in equation \ref{eq:embedding-BCCB-matrix-vector-product}, using the fast calculation of the eigenvalues of BCCB matrices (equation \ref{eq:fft_BCCB_column_2D}) and using the same previous Kronecker product property, the auxiliary matrix-vetor product $\mathbf{w} = \mathbf{C} \mathbf{v}$ can be rewritten as follows:

\begin{equation}
\mathbf{F}_{(2 N_x)}^{\ast} \left[ \mathbf{L} \circ \left( \mathbf{F}_{(2N_x)} \mathbf{V} \, \mathbf{F}_{(2N_y)} \right) \right] \mathbf{F}_{(2N_y)}^{\ast} = \mathbf{W} \: ,
\label{eq:fft_q}
\end{equation}

\noindent where ``$\circ$'' denotes the Hadamard product, $\mathbf{L}$ is a $2N_x \times 2N_y$ row-oriented matrix containing the eigenvalues of $\mathbf{C}$, and $\mathbf{V}$ and $\mathbf{Q}$ are $2N_x \times 2N_y$ row-oriented matrices obtained from the vectors $\mathbf{v}$ and $\mathbf{q}$.

Note that in general, the first column of blocks forming a BCCB matrix $\mathbf{C}_{\ell}$ (equation \ref{eq:circulant_elements}) is given by:

\begin{equation}
\left[\mathbf{C} \right]_{(0)} = 
\begin{bmatrix}
\mathbf{C}_{0} \cr
\mathbf{C}_{1} \cr
\vdots \cr
\mathbf{C}_{N_x-2} \cr
\mathbf{C}_{N_x-1} \cr
\mathbf{0} \cr
\mathbf{C}_{N_x-1} \cr
\mathbf{C}_{N_x-2} \cr
\vdots \cr
\mathbf{C}_{1}
\end{bmatrix} \; ,
\end{equation}
where each block $\mathbf{C}_{\ell}$, $\ell = 0, \dots, N_x-1$, is a $2N_y \times 2N_y$ circulant matrix and $\mathbf{0}$ is a $2N_y \times 2N_y$ matrix with all elements equal to zero. Thus, the first column $\mathbf{c}_{0}$ of a circulant matrix $\mathbf{C}$ is given by:

\begin{equation}
\mathbf{c}_{0} =
\begin{bmatrix}
	a_{00} \cr
	a_{10} \cr
	\vdots \cr
	a_{(N_y-2)0} \cr
	a_{N_y-1) 0} \cr
	0 \cr
	a_{N_y-1) 0} \cr
	a_{(N_y-2)0} \cr
	\vdots \cr
	a_{10}
\end{bmatrix} \:.
\end{equation}

To complete the process, after calculating the inverse to obtain $\mathbf{W}$ it is necessary to rearrange its rows to obtain the vector $\mathbf{w}$ and also rearrange the elements of $\mathbf{w}$ to obtain the wanted vector $\mathbf{d(p)}$.

%The algorithm for computing the matrix-vector product $\mathbf{A}\mathbf{p}$ and obtaining the resulting vector $\mathbf{d(p)}$ can be summarized in the following steps:

%1. Compute the first column of the embedded $4N_x N_y \times 4N_x N_y$ BCCB matrix $\mathbf{C}$ by using the first column of the $N_x N_y \times N_x N_y$ BTTB matrix $\mathbf{A}$;

%2. Compute the eigenvalues of $\mathbf{C}$ rearranging them in rows of the $2N_x \times 2N_y$ matrix $\mathbf{L}$;

%3. Rearrange the vector $\mathbf{v}$ in the rows of the $2N_x \times 2N_y$ matrix $\mathbf{V}$;

%4. Compute the Hadammard product $\mathbf{L} \circ \tilde{\mathbf{P}}$, where $\tilde{\mathbf{P}} = \mathbf{F}_{(2N_x)} \mathbf{P} \, \mathbf{F}_{(2N_y)}$ is computed by using a fast algorithm for 2D DFT;

%5. Compute the resulting $2N_x \times 2N_y$ matrix $\mathbf{Q} = \mathbf{F}_{(2N_x)}^{\ast} \left[ \mathbf{L} \circ \tilde{\mathbf{P}}\right] \mathbf{F}_{(2N_y)}^{\ast}$ by using a fast algorithm for inverse 2D DFT;

%6. Rearrange the rows of $\mathbf{Q}$ to obtain the vector $\mathbf{q}$;

%7. Rearrange the elements of $\mathbf{q}$ to obtain the vector $\mathbf{d(p)}$.


\subsection{Computational performance}
In a normal procedure of the fast equivalent layer proposed by \citet{siqueira-etal2017}, at each iteration a full matrix $\tensor{A}$ (equation \ref{eq:predicted-data-vector}) is multiplied by the estimated mass distribution parameter vector $\hat{\mathbf{p}}^k$ producing the predicted gravity data $\mathbf{d(p)}$  iteratively. As pointed in \citet{siqueira-etal2017} the number of flops (floating-point operations) necessary to estimate the $N$-dimensional parameter vector inside the iteration loop is

\begin{equation}
f_0 = N^{it} (3N + 2N^2) \; ,
\label{eq:float_classic}
\end{equation}

\noindent where $N^{it}$ is the number of iterations. From equation \ref{eq:float_classic} it is clear that the matrix-vector product ($2N^2$) accounts for most of the computational complexity in this method.

It is well known that FFT takes $2 N \log_2(N)$ flops \citep{chu1999inside}. Computing the eigenvalues of the BCCB matrix ($4N \times 4N$) and applying 2D-FFT on the parameter row-oriented matrix $\mathbf{V}$ (equation \ref{eq:fft_q}), takes $8N \log_2(4N)$ each. However, the sensitivity matrix does not change during the process thus, the eigenvalues of BCCB must be calculated only once, outside of the iteration. The multiplication of two complex numbers takes four real multiplications and two additions, which brings 6 times $4N$ flops to carry the Hadamard product. As it is necessary to compute the inverse FFT, another $8N \log_2(4N)$ must be taken in account. This lead us to a flops count in our method of

\begin{equation}
f_1 = 8N\log_2(4N) + N^{it} (27N + 16N\log_2(4N)).
\label{eq:float_bccb}
\end{equation}

Another major improvement of this methodology is the exoneration of calculating the full sensibility matrix $\tensor{A}$ (equation \ref{eq:predicted-data-vector}). Each element needs $12$ flops (equation \ref{eq:aij}), totalizing $12N^2$ flops for the full matrix. Calculating a single column of the BTTB matrix requires $12N$ flops.
Thus, the full flops count of the method presented by \citet{siqueira-etal2017} is

\begin{equation}
f_s = 12N^2 + N^{it} (3N + 2N^2),
\label{eq:float_siqueira}
\end{equation}

and it is decreased in our method to

\begin{equation}
f_f = 12N + 8N \log_2(4N) + N^{it} (27N + 16N\log(4N)).
\label{eq:float_new}
\end{equation}

Figure \ref{fig:float} shows the floating points to estimate the parameter vector using the fast equivalent layer by using the method of \citet{siqueira-etal2017} (equation \ref{eq:float_classic}) and our approach (equation \ref{eq:float_bccb}) versus the number of observation points varyig from $N = 5000$ to $N = 1\,000\,000$ with $50$ iterations. The number of operations is drastically decreased.

Table 1 shows the system RAM memory usage needed to store the full sensitivity matrix, the single column of the sensitivity matrix to form the BTTB matrix and the BCCB eigenvalues ($8$ times greater than that required by the BTTB first column). The quantities were computed for different numbers of data (N) with the same corresponding number of equivalent sources (N). Table 1 considers that each element of the matrix is a double-precision number, which requires 8 bytes of storage, except for the BCCB complex eigenvalues, which requires 16 bytes per element. Notice that $1\,000\,000$ observation points requires nearly $7.6$ Terabytes of RAM memory to store the whole sensibility matrix of the equivalent layer.

Using a PC with a Intel Core i7 4790@3.6GHz processor and 16 Gb of RAM memory, Figure \ref{fig:time_comparison}  compares the running time  of the  \citet{siqueira-etal2017} method with the one of our work, considering a constant number of iterations equal to 50. Clearly, the major advantage of our approach is its computational efficiency that allows a rapid calculation of the gravity forward modeling  with number of observations greater than $10\,000$. Because of the RAM available in this system, we could not perform this comparison with more observations. Therefore, the number of observation is limited to $22\,500$. Disregarding the RAM limitation, Figure \ref{fig:time_bccb} shows the running time of our method with 50 iterations and with the number of observations up to  25 millions. Our method requires 26:8 seconds to run one million of observations, whereas \citet{siqueira-etal2017} method took 48:3 seconds to run $22\,500$ observations


\section{Synthetic tests}
In this section, we  investigate the effectiveness of using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product})  to solve, at each iteration, the forward modeling (the matrix-vector product $\mathbf{A} \hat{\mathbf{p}}^k$)  required in the fast equivalent-layer method proposed by \citet{siqueira-etal2017}.  We simulated three sources whose horizontal projections are shown in Figure \ref{fig:synthetic_data} as black lines.  These sources are two vertical prisms with density contrasts of $0.35\, \mathrm{g/cm^3}$ (upper-left prism) and $0.4\, \mathrm{g/cm^3}$ (upper-right prism) and a sphere with radius of $1\,000$ m with density contrast of $-0.5\, \mathrm{g/cm^3}$. Figure \ref{fig:synthetic_data}  shows the vertical component of gravity field generated by these sources contaminated with additive pseudorandom Gaussian noise with zero mean and standard deviation of $0.015$ mGal.
 
The advantage of using the structures of BTTB and BCCB matrices to compute forward modeling in  the fast-equivalent layer method \cite[]{siqueira-etal2017} is grounded on the use of regular grids of data and equivalent sources. Hence, we created $10\,000$ observation points regularly spaced in a grid of $100 \times 100$ at $100$ m height. We also set a grid of equivalent point masses, each one directly beneath each observation points, located at $300$ m deep.  Figures \ref{fig:classic_fast_val}a and \ref{fig:bccb_fast_val}a  show the fitted gravity data obtained, respectively, by the fast equivalent layer method and by our modified form of this method that computes the forward modeling using equation \ref{eq:embedding-BCCB-matrix-vector-product}. The corresponding residuals (Figures \ref{fig:classic_fast_val}b and \ref{fig:bccb_fast_val}b), defined as the difference between the observed (Figure  \ref{fig:synthetic_data}) and fitted gravity data (Figures \ref{fig:classic_fast_val}a and \ref{fig:bccb_fast_val}a), show means close to zero  and standard deviations of 0.0144 mGal.  Therefore, Figures \ref{fig:classic_fast_val} and \ref{fig:bccb_fast_val} show that \citet{siqueira-etal2017} method and our modified version of this method produced virtually the same results. This excellent agreement is confirmed in Figures \ref{fig:delta_comparison} and \ref{fig:delta_rho} which shows that there are virtually no differences, respectively,  in the fitted data presented in Figures \ref{fig:classic_fast_val}b and \ref{fig:bccb_fast_val}b and in the estimated mass distributions within the equivalent layers (not shown) yielded by both \citet{siqueira-etal2017} method and our modification of this method.  These results (Figures \ref{fig:delta_comparison} and \ref{fig:delta_rho})  show that computing the matrix-vector product ($\mathbf{A} \hat{\mathbf{p}}^k$), required in the forward modeling, by means of embedding the BTTB matrix into a BCCB matrix (equation \ref{eq:embedding-BCCB-matrix-vector-product}) yields practically the same result as the one produced by computing this matrix-vector product  with a full matrix $\mathbf{A}$ as used in \citet{siqueira-etal2017}.

We perform two forms of processing the gravity data (Figure \ref{fig:synthetic_data}) through the equivalent layer technique: the upward (Figure \ref{fig:upward_comparison}) and the downward (Figure \ref{fig:downward_comparison}) continuations. The upward height is 300 m and the downward  is at 50 m.   Either in the upward continuation (Figure \ref{fig:upward_comparison}) or in the downward continuation (Figure \ref{fig:downward_comparison}), the continued gravity data using the fast equivalent layer proposed by \citet{siqueira-etal2017} (Figures \ref{fig:upward_comparison}a and \ref{fig:downward_comparison}a) are in close agreement with those produced by our modification of \citet{siqueira-etal2017} method (Figures \ref{fig:upward_comparison}b and \ref{fig:downward_comparison}b). The residuals (Figures \ref{fig:upward_comparison}c and \ref{fig:downward_comparison}c) quantify this agreement since their means and standard deviations are close to zero in both continued gravity data using both methods.  All the continued gravity data shown here (Figures \ref{fig:upward_comparison} and \ref{fig:downward_comparison}) agree with the true ones (not shown). The most striking feature of these upward or the downward continuations concerns the total computation time. The computation time spent by our method is approximately $1\,500$ times faster than \citet{siqueira-etal2017} method. 


\section{Real data test}
Test with real data are conducted with the gravity data from Caraj\'as, north of Brazil, were provided by the  Geological Survey of Brazil (CPRM). The real aerogravimetric data were collected in 113 flight lines along north–south direction with flight line spacing  of 3 km and tie lines along east–west direction at 12 km.

This airborne gravity survey was divided in two different areas, collected in different times, having samples spacing of 7.65 m and 15.21 m, totalizing  4,353,428 observation points. The height of the flight was fixed at 900 m. The gravity data (Figure \ref{fig:carajas_real_data}) were gridded into a regularly spaced dataset of $250\,000$ observation points ($500 \times 500$) with a grid spacing of $716.9311$ km north-south and $781.7387$ km east-west.

To apply our modification of the fast equivalent-layer method \cite[]{siqueira-etal2017}  that computes the forward modeling using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}), we set an equivalent layer at 300 m deep. Figure \ref{fig:carajas_gz_predito_val}a shows the fitted gravity data after 50 iterations by applying our method. The residuals (Figure \ref{fig:carajas_gz_predito_val}b), defined as the difference between the observed (Figure \ref{fig:carajas_real_data}) and the predicted (Figure \ref{fig:carajas_gz_predito_val}a) data,  show an acceptable data fitting because they have a mean close to zero (0.0003 mGal) and a small standard deviation of 0.105 mGal which corresponds to approximately 0.1 \% of the amplitude of the gravity data.

These small residuals indicate that our method yielded an estimated mass distribution (not shown) that can be used in the data processing. We perform upward-continuation of the real gravity data (Figure \ref{fig:carajas_real_data}) at a constant height of $5\,000$ m over the real data. The upward-continued gravity data (Figure \ref{fig:up2000_carajas_500x500}) seem a reasonable processing because of the attenuation of the short wavelenghts. By using our approach, the processing of the $250\,000$ observations was extremely fast and took 0.216 seconds.


\section{Conclusions}
By exploring the Block-Toeplitz Toeplitz-block (BTTB) structure of the sensitivity matrix in the gravity data processing, we have proposed a new efficient approach for calculating the gravity-data forward modeling required in the iterative fast equivalent-layer technique grounded on excess mass constraint that does not demand  the solution of linear systems.  Its efficiency requires the use of regular grids of observations and equivalent sources (point masses). Our algorithm greatly reduces the number of  flops necessary to estimate a 2D mass distribution within the equivalent layer that fits the observed gravity data. For example, when processing one million observations the number of flops is reduced in 104 times. Traditionally, such amount of data impractically requires 7.6 Terabytes of RAM memory to handle the full sensitivity matrix. Rather, in our method, this matrix takes 61.035 Megabytes of RAM memory only.

Our method takes advantage of the symmetric BTTB system that arises when processing a harmonic function and considering that either the observations or the sources of the interpretative model (point of masses over the equivalent layer) are distributed on regular grids. Symmetric BTTB matrices can be stored by using only a single column and can be embedded into a symmetric BCCB matrix, which in turn also only needs a single column. 
This means that only a single column  of the sensitivity matrix needs to be calculated.  Once the jth column of the sensitivity matrix represents the influence of the jth source (jth point mass) has on the predicted data, our method only requires a single point mass that set up the equivalent layer to compute the gravity-data forward modeling.

Using the fast Fourier transform it is possible to calculate the eigenvalues of BCCB matrices which can
be used to compute a matrix-vector product (gravity-data forward modeling) in a very low computational cost. We have successfully applied the proposed method to upward (or downward) synthetic gravity data. Testing on field data from the Caraj\'as Province, north of Brazil, confirms the potential of our approach in upward-continuing  gravity data with $250\,000$ observations in  about 0.2 seconds.  Our method allows, in future research, applying the equivalent layer-technique for processing and interpreting massive data set such as collected in continental and global scales studies.

\newpage



\subsection*{Figures}
\renewcommand{\figdir}{Fig} % figure directory

Figure~\ref{fig:float}

\plot{float}{width=\textwidth}
{floating points to estimate the parameter vector using the fast equivalent layer using \citet{siqueira-etal2017} method (equation \ref{eq:float_classic}) and our approach (equation \ref{eq:float_bccb}) versus the numbers of observation points varyig from $N = 5\,000$ to $N = 1\,000\,000$ with $50$ iterations. The number of operations is drastically decreased.}
\newpage

Figure~\ref{fig:time_comparison}

\plot{time_comparison}{width=10cm}
{time necessary to run 50 iterations of the \citet{siqueira-etal2017} method and the one presented in this work. With the limitation of $16$ Gb of RAM memory in our system, we could test only up to $22\,500$ obervation points.}

Figure~\ref{fig:time_bccb}

\plot{time_bccb}{width=10cm}
{time necessary to run the equivalent layer technique with 50 iterations using our approach, where the RAM is not a limitation factor. We could run up to $25$ million observation points. In comparison, $1$ million observation points took $26.8$ seconds to run, where the maximun $22\,500$ observation points in Figure \ref{fig:time_comparison}, with \citet{siqueira-etal2017} method, took 48:3 seconds.}
\newpage

Figure~\ref{fig:synthetic_data}

\plot{synthetic_data}{width=13.5cm}
{Noise-corrupted gravity data (in color map) produced by three simulated sources  whose horizontal projections are shown in black lines. The simulated sources are: two polygonal prisms, with density contrast of $0.35\, \mathrm{g/cm^3}$ (upper-left body) and $0.4\, \mathrm{g/cm^3}$ (upper-right body), and a sphere with radius of $1\,000$ m with density contrast	of $-0.5\, \mathrm{g/cm^3}.$}
\newpage

Figure~\ref{fig:classic_fast_val}

\plot{classic_fast_val}{width=8cm}
{(a) Fitted gravity data produced by the fast equivalent-layer technique proposed by \citet{siqueira-etal2017}. (b) Gravity residuals, defined as the difference between the observed data in Figure \ref{fig:synthetic_data} and the predicted data in panel a, with their mean of $8.264e^{-7}$ and standard deviation of $0.0144$ mGal.}
\newpage

Figure~\ref{fig:bccb_fast_val}

\plot{bccb_fast_val}{width=8cm}
{(a) Fitted gravity data produced by our modification of the fast equivalent layer \citep{siqueira-etal2017}. (b) Gravity residuals, defined as the difference between the observed data in Figure 4 and the predicted data in panel a, with their mean of $8.264e^{-7}$ and standard deviation of $0.0144$ mGal.}
\newpage

Figure~\ref{fig:delta_comparison}

\plot{delta_comparison}{width=13.5cm}
{Difference between the fitted gravity data produced by \citet{siqueira-etal2017} method (Figure \ref{fig:classic_fast_val}a) and by our modified form of this method (Figure \ref{fig:bccb_fast_val}a) that computes the forward modeling using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}).}
\newpage

Figure~\ref{fig:delta_rho}

\plot{delta_rho}{width=13.5cm}
{Difference between the estimated mass distribution within the equivalent layer produced by \citet{siqueira-etal2017} method (Figure \ref{fig:classic_fast_val}) and by our modified form of this method (Figure \ref{fig:bccb_fast_val}) that computes the forward modeling using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}).}
\newpage

Figure~\ref{fig:upward_comparison}

\plot{upward_comparison}{width=5cm}
{The upward-continued gravity data using: (a) the fast equivalent layer proposed by \citet{siqueira-etal2017} and (b) our modified form of \citet{siqueira-etal2017} method by using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}) to calculate the forward modeling.  (c) Residuals, defined as the difference between panels a and b with their mean of $-5.938e^{-18}$ and standard deviation of $8.701e^{-18}$.  The total computation times in the \citet{siqueira-etal2017} method and in our approach are $7.62026$ and $0.00834$ seconds, respectively.}
\newpage

Figure~\ref{fig:downward_comparison}

\plot{downward_comparison}{width=5cm}
{The downward-continued gravity data using: (a) the fast equivalent layer proposed by \citet{siqueira-etal2017} and (b) our modified form of \citet{siqueira-etal2017} method by using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}) to calculate the forward modeling.  (c) Residuals, defined as the difference between panels a and b with their mean of $5.914e^{-18}$ and standard deviation of $9.014e^{-18}$.  The total computation times in the \citet{siqueira-etal2017} method and in our approach are $7.59654$ and $0.00547$ seconds, respectively.}
\newpage

Figure~\ref{fig:carajas_real_data}

\plot{carajas_real_data}{width=13.5cm}
{Caraj\'as Province, Brazil. Gravity data on a regular grid of $500 \times 500$ points, totaling $250,000$ observations. The inset shows the study area (blue rectangle) which covers the southeast part of the state of Par\'a, north of Brazil.}
\newpage

Figure~\ref{fig:carajas_gz_predito_val}

\plot{carajas_gz_predito_val}{width=8cm}
{Caraj\'as Province, Brazil. (a) Predicted gravity data produced by our modification of the fast equivalent-layer method \citep{siqueira-etal2017}  that computes the forward modeling using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}). (b) Gravity residuals, defined as the difference between the observed data in Figure \ref{fig:carajas_real_data} and the predicted data in panel a, with their mean of 0.000292 mGal and standard deviation of $0.105$ mGal.}
\newpage

Figure~\ref{fig:up2000_carajas_500x500}

\plot{up2000_carajas_500x500}{width=13.5cm}
{Caraj\'as Province, Brazil. The upward-continued gravity data using our modification of the fast equivalent layer method \citep{siqueira-etal2017} that computes the forward modeling using the properties of BTTB and BCCB matrices (equation \ref{eq:embedding-BCCB-matrix-vector-product}). The total computation time is 0.216 seconds for processing of the $250,000$ observations.}
\newpage

%\subsubsection{Multiplot} 
%Sometimes it is convenient to put two or more figures from different
%files in an array (see Figure~\ref{fig:exph,exgr}). Individual plots
%are Figures~\ref{fig:exph} and~\ref{fig:exgr}.
%
%\multiplot{2}{exph,exgr}{width=0.4\textwidth}
%{This figure is specified in the document by \newline \texttt{
%    $\backslash$multiplot\{2\}\{exph,exgr\}\{width=0.4$\backslash$textwidth\}\{This caption.\}}.
%}
%
%The first argument of the \texttt{multiplot} command specifies the
%number of plots per row.

\subsection{Tables}

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{$N \times N$} & \textbf{Full RAM (Mb)} & \textbf{BTTB RAM (Mb)}  & \textbf{BCCB RAM (Mb)}\\
			\hline 
			$100 \times 100$ & 0.0763 & 0.0000763 & 0.0006104\\
			\hline
			$400 \times 400$ & 1.22 & 0.0031 & 0.0248\\
			\hline
			$2\,500 \times 2\,500$ & 48 & 0.0191 & 0.1528\\
			\hline
			$10\,000 \times 10\,000$ & 763 & 0.00763 & 0.6104\\
			\hline
			$40\,000 \times 40\,000$ & 12\,207 & 0.305 & 2.4416 \\
			\hline
			$250\,000 \times 250\,000$ & 476\,837 & 1.907 & 15.3 \\
			\hline
			$500\,000 \times 500\,000$ & 1\,907\,349 & 3.815 & 30.518 \\
			\hline
			$1\,000\,000 \times 1\,000\,000$ & 7\,629\,395 & 7.629 & 61.035 \\
			\hline
		\end{tabular}
		\caption{Comparison between the system RAM memory usage needed to store the full matrix, the BTTB single column of the sensitivity matrix and the BCCB eigenvalues (eight times greater than the BTTB singel column). The quantities were computed for different numbers of data (N) with the same corresponding number of equivalent sources (N). This table considers that each element of the matrix is a double-precision number, which requires 8 bytes of storage, except for the BCCB complex eigenvalues, which requires 16 bytes per element.}
	\end{center}
\end{table} 

%The discussion is summarized in Table~\ref{tbl:example}.
%
%\tabl{example}{This table is specified in the document by \texttt{
%    $\backslash$tabl\{example\}\{This caption.\}\{\ldots\}}.
%}{
%  \begin{center}
%    \begin{tabular}{|c|c|c|}
%      \hline
%      \multicolumn{3}{|c|}{Table Example} \\
%      \hline
%      migration\rule[-2ex]{0ex}{5ex} & 
%      $\omega \rightarrow k_z$ & 
%      $k_y^2+k-z^2\cos^2 \psi=4\omega^2/v^2$ \\
%      \hline
%      \parbox{1in}{zero-offset\\diffraction}\rule[-4ex]{0ex}{8ex} &
%      $k_z\rightarrow\omega_0$ &
%      $k_y^2+k_z^2=4\omega_0^2/v^2$ \\
%      \hline
%      DMO+NMO\rule[-2ex]{0in}{5ex} & $\omega\rightarrow\omega_0$ & 
%      $\frac{1}{4}
%      v^2k_y^2\sin^2\psi+\omega_0^2\cos^2\psi=\omega^2$ \\
%      \hline
%      radial DMO\rule[-2ex]{0in}{5ex} & $\omega\rightarrow\omega_s$ &
%      $\frac{1}{4}v^2k_y^2\sin^2\psi+\omega_s^2=\omega^2$\\
%      \hline
%      radial NMO\rule[-2ex]{0in}{5ex} & $\omega_s\rightarrow\omega_0$ &
%      $\omega_0\cos\psi=\omega_s$\\
%      \hline
%    \end{tabular}
%  \end{center}
%}

%\section{ACKNOWLEDGMENTS}

%This study was financed by the brazilian agencies CAPES (in the form of a scholarship), FAPERJ (grant n.$^{\circ}$ E-26 202.729/2018) and CNPq (grant n.$^{\circ}$ 308945/2017-4).

%\append{Appendix example}

%\append[equations]{Another appendix}

%\sideplot{errgrp}{width=0.8\textwidth}
%{This figure is specified in the document by \texttt{
%    $\backslash$sideplot\{errgrp\}\{width=0.8$\backslash$text\-width\}\{This caption.\}}.


%\append{The source of this document}

%\verbatiminput{geophysics_example.ltx}

%\append{The source of the bibliography}

%\verbatiminput{example.bib}

\newpage

\bibliographystyle{seg}  % style file is seg.bst
\bibliography{references}

\end{document}
